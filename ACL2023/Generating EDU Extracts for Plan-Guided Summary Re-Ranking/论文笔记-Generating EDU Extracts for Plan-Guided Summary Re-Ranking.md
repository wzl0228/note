# Generating EDU Extracts for Plan-Guided Summary Re-Ranking

[原论文地址](https://aclanthology.org/2023.acl-long.151.pdf)

## 论文摘要
二步方法，是指在生成摘要候选后重新排序，以返回单个摘要的方法，与比标准一步方法相比可以提高ROUGE得分。然而，标准解码方法(如波束搜索（beam search）、核心样本（nucleus sampling）、多样化波束搜索（diverse beam search）)会产生冗余，往往是质量较低的内容。为了解决该问题，我们设计了一种新方法通过重新排序生成摘要候选者。我们将每个候选摘要建立在其独特的内容计划上，并使用模型的top beam生成计划指导(plan-guided)的摘要。具体来说，一个标准语言模型(一个BART LM)自回归地使用提取复制机制生成基本语言单元(Elemental Discourse Unit，EDU)内容计划。内容计划生成器中的top K beams然后将用于指导一个单独的LM，为每个特定计划生成一个单独抽象候选者。我们将重新排序器(BRIO)应用于我们生成摘要候选者的过程，也是我们解码方法的基准。我们的方法在CNN / Dailymail、NYT和Xsum中，ROUGE-2 F1得分分别提高了0.88、2.01和0.38。CNN/DM的人类评估验证了这些结果。类似地，在CNN/DM中的1,000个样本中，我们发现提示GPT-3按照EDU计划比基于样本的方法在ROUGE-2 F1得分上提高了1.05个点。

## 面临的问题

## 主要工作
1. 还探讨了通过不同的计划实现不同的摘要，但我们专注于有根据的提取计划，该计划通过鼓励模型关注源文本的特定、独特部分来促进多样性。

> 内容计划（content plan）：源文档的一组不重叠的文本片段。
> EDU：EDUs代表句子独立子句，支持比句子级别提取更细粒度的抽取。本文将EDUs作为content paln的合适的粒度。

2. 在高层，我们采用了两个编码器-解码器模型。给定一个文档，第一个模型通过波束搜索生成K个唯一的内容计划。然后，每个内容计划都被用作第二个模型的指南，该模型在给定计划和文档的情况下实现抽象。具体而言，基于BART（Lewis等人，2020）的分层编码器-解码器通过复制EDU来学习从左到右生成提取，直到复制特定的提取结束令牌。
这些提取计划用于装饰输入文件，并作为计划导向摘要（PGA）的指南。顶部的K个波束是从内容规划器返回的，而只有顶部波束被返回用于计划实现，以避免去生成。
来自CNN/DaylyMail新闻数据集的训练过程示例如图1所示。
