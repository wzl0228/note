# 项目微调大模型实验记录
## t5_pegasus
### 使用t5_pegasus base
参数量2.75亿，batch_size=1，lr=2e-4，max_len=max_generate_len=256

数据集“过滤”以后保留text文本不超过256长度的数据。（text的长度大于等于summary的长度）

数据集  | train | dev | test
---- | ----- | ----- | -----
数量  | 73 | 6 | 15
比例  | 0.78 | 0.06 | 0.16

模型评估结果采用Rouge1、Rouge2、RougeL评估，在训练过程中保留模型只采用RougeL指标

评估结果（保留小数点后4位）  | RG-1 | RG-2 | RG-L
---- | ----- | ----- | -----
t5_pegasus_fintune256  | 0.3707 | 0.2019 | 0.3137
