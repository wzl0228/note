# 两阶段意见摘要模型实验记录
[代码](https://github.com/wzl0228/amasum_review_summ)
## 1.处理数据集
### （1）数据集路径问题、amasum数据集格式转换成对话摘要数据集的格式
### （2）统计单条review分词以后的长度、统计gold_summary分词以后的长度。
确定max_src_ntokens_per_sent，超过该参数，reiew截断
确定max_tgt_len，超过该参数，summary截断
### （3）preprocess.py数据预处理时，贪心选取tgt_label，增加了verdict、pros、cons分别贪心选取，求并集，希望抽取出来的句子更多
设置"整体、verdict、pros、cons"四部分贪心选取review的长度上限都700，太大，发生问题
设置"整体、verdict、pros、cons"四部分贪心选取review的长度上限整体为500（原参数），v/p/c都为150，待验证，目前正常运行，等待结果

## 2.复现对话摘要模型结果
模型  | RG-1 | RG-2 | RG-L
---- | ----- | ----- | -----
原模型  | 36.81 | 19.63 | **29.61**
复现（脱敏数据）| **42.93** | **20.68** | 28.90

在脱敏数据上的复现效果较好，说明模型指标正常
## 3.两阶段意见摘要模型
### （1）未分开三部分且直接利用分词结果评估
模型  | RG-1 | RG-2 | RG-L
---- | ----- | ----- | -----
SelSum-Verdict  | 24.33 | **5.29** | 18.84
SelSum-Pros | 21.29 | 4.00 | **19.39**
SelSum-Cons | 14.96 | 2.60 | 13.07
MyModel-e1(V+P+C) | 25.98 | 5.25 | 19.00
MyModel-e2(V+P+C) | **26.04** | 5.28 | 19.06

SelSum模型分三部分评估，我合并评估，并且是分词之后的结果评估，用分词后的结果评估不合理，且需要分开三部分评估才能和原模型指标对比。
### （2）分开三部分评估，还未合并单词
模型  | V-R1 | V-R2 | V-RL | P-R1 | P-R2 | P-RL | C-R1 | C-R2 | C-RL 
---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- 
SelSum | **24.33** | **5.29** | **18.84** | **21.29** | **4.00** | **19.39** | **14.96** | **2.60** | **13.07**
MyModel-e1 | 20.85 | 4.73 | 15.88 | 16.80 | 3.09 | 10.84 | 8.14 | 1.42 | 6.26
MyModel-e2 | 19.59 | 4.41 | 14.85 | 16.90 | 2.95 | 10.83 | 9.16 | 1.50 | 7.06
MyModel-w/o-topic | 20.19 | 4.14 | 15.24 | 16.66 | 2.85 | 10.65 | 8.35 | 1.51 | 6.53

修改评估正确以后，指标掉的很多，说明原来的代码有问题，分析原因是合并评估的分隔符会被认为是匹配。

主题模型加不加效果变化不大，说明主题模型存在问题，需要修改。发现问题在于主题表示为【all主题表示，随机，随机】，主题向量有两部分都是随机的，主题表示的效果肯定存在问题。

#### （2.1）对比强化学习前后模型指标的变化情况，以MyModel-e1为例：
模型  | V-R1 | V-R2 | V-RL | P-R1 | P-R2 | P-RL | C-R1 | C-R2 | C-RL 
---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- 
MyModel-e1-pre | 20.80 | 4.68 | 15.85 | **16.81** | 3.09 | **10.88** | 8.08 | 1.38 | 6.18
MyModel-e1（rl） | **20.85** | **4.73** | **15.88** | 16.80 | **3.09** | 10.84 | **8.14** | **1.42** | **6.26**

说明强化学习起作用了的，可能不会提升特别多的指标，但是会提高。

### （3）修改主题模型的主题表示，打开/关闭主题模型的后评估
模型  | V-R1 | V-R2 | V-RL | P-R1 | P-R2 | P-RL | C-R1 | C-R2 | C-RL 
---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- 
MyModel-BOW*3 | 20.09 | 4.39 | 15.14 | 17.02 | 3.00 | 10.83 | 8.97 | 1.67 | 6.92
MyModel-BOW*1 | 20.27 | 4.32 | 15.28 | 16.93 | 2.93 | 10.73 | 8.46 | 1.56 | 6.57
MyModel-w/o-topic | 20.39 | 4.59 | 15.28 | 17.02 | 3.09 | 10.87 | 8.82 | 1.57 | 6.79

#### （3.1）对比主题模型用【all主题表示，all主题表示，all主题表示】（BOW-3）和【all主题表示】（BOW-1）的效果
模型  | V-R1 | V-R2 | V-RL | P-R1 | P-R2 | P-RL | C-R1 | C-R2 | C-RL 
---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- 
MyModel-BOW-3 | 20.09 | **4.39** | 15.14 | **17.02** | **3.00** | **10.83** | **8.97** | **1.67** | **6.92**
MyModel-BOW-1 | **20.27** | 4.32 | **15.28** | 16.93 | 2.93 | 10.73 | 8.46 | 1.56 | 6.57

说明：主题模型BOW-3的效果比BOW-1的效果好

#### （3.2）对比主题模型打开关闭前后（BOW-3）和（w/o-topic）的效果
模型  | V-R1 | V-R2 | V-RL | P-R1 | P-R2 | P-RL | C-R1 | C-R2 | C-RL 
---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- 
MyModel-BOW*3 | 20.09 | 4.39 | 15.14 | 17.02 | 3.00 | 10.83 | **8.97** | **1.67** | **6.92**
MyModel-w/o-topic | **20.39** | **4.59** | **15.28** | **17.02** | **3.09** | **10.87** | 8.82 | 1.57 | 6.79

说明：关闭主题模型的效果比打开的效果好，那主题模型相当于不起作用，我们需要进一步修改主题模型

### （4）合并单词后，重复（3）的实验，验证结论的正确性
模型  | V-R1 | V-R2 | V-RL | P-R1 | P-R2 | P-RL | C-R1 | C-R2 | C-RL 
---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- 
MyModel-BOW*3 | 20.01 | 3.33 | 15.09 | 17.32 | 2.54 | 11.23 | 8.87 | 1.38 | 6.90
MyModel-BOW*1 | 19.90 | 3.35 | 15.08 | 17.03 | 2.59 | 11.03 | 8.82 | 1.43 | 6.88
MyModel-w/o-topic | 20.26 | 3.43 | 15.13 | 17.62 | 2.77 | 11.42 | 8.90 | 1.44 | 6.98

合并单词匹配和分词匹配的指标有差距。

#### （4.1）对比BOW-3和BOW-1
模型  | V-R1 | V-R2 | V-RL | P-R1 | P-R2 | P-RL | C-R1 | C-R2 | C-RL 
---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- 
MyModel-BOW*3 | **20.01** | 3.33 | **15.09** | **17.32** | 2.54 | **11.23** | **8.87** | 1.38 | **6.90**
MyModel-BOW*1 | 19.90 | **3.35** | 15.08 | 17.03 | **2.59** | 11.03 | 8.82 | **1.43** | 6.88

#### （4.2）对比BOW-3和w/o-topic
模型  | V-R1 | V-R2 | V-RL | P-R1 | P-R2 | P-RL | C-R1 | C-R2 | C-RL 
---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- 
MyModel-BOW*3 | 20.01 | 3.33 | 15.09 | 17.32 | 2.54 | 11.23 | 8.87 | 1.38 | 6.90
MyModel-w/o-topic | **20.26** | **3.43** | **15.13** | **17.62** | **2.77** | **11.42** | **8.90** | **1.44** | **6.98**

w/o-topic > BOW-3 > BOW-1

### （5）修改主题模型表示为【verdict主题表示，pros主题表示，cons主题表示】，使用一个解码器，修改了数据预处理的贪心选择标签时的分词合并。

模型  | V-R1 | V-R2 | V-RL | P-R1 | P-R2 | P-RL | C-R1 | C-R2 | C-RL 
---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- 
MyModel-1de-w/o rl | 20.09 | 3.40 | 15.20 | 17.06 | 2.59 | 10.98 | **9.26** | **1.53** | **7.22**

**可以看到预处理部分调整了贪心策略后，对缺点部分的摘要指标（对比（4））有明显提高。**

存在问题：

1. 首先需要用三个解码器三个生成器，并且需要添加线性层去把主题表示映射为三个，这样才更合理。
2. mask的过程主题模型的处理针对的是对话摘要的agent和cust，需要去除这部分相关的操作，因为我们的文本并不存在这个标签。


### （6）修改主题模型表示为【verdict主题表示】，【pros主题表示】，【cons主题表示】，使用三个解码器。

解决bug：
1. 主要问题是线性层映射以后的维度问题。
2. retain_graph=True指定在计算梯度时保留计算图，以便后续的反向传播或访问中间结果。将一个解码器变为三个，对应生成器的loss在计算梯度过程中，要注意梯度的保留，三个部分梯度叠加需要前两个部分保留，最后一个设置retain_graph=False释放。
3. 评估问题：需要对生成的verdict、pros、cons进行拼接成格式list(torch.tensor)，评估需要对三部分之间添加额外的分隔符[unused12]。

可能存在的问题：
1. 应该把贪心抽取出来的句子（标签）对应三个部分，编码器部分修改，主题模型部分修改？
2. 模型现在相当于利用选出的评论，通过三个解码器（分别对应三部分主题表示），通过三个生成器生成三部分摘要。评估是分开三部分对应评估pred和gold，但是在强化学习阶段，如果是对整体的pred和gold计算rouge值评估，则需要把分隔符[unused13]和[unused12]统一（或对应三部分的rouge值之差作为强化学习的reward）
3. reward只计算了rouge-l的差作为reward，需不需要更改为三部分之和。
4. 主题表示的mask逻辑，主题表示的维度100*100（能否保存足够的主题信息）
5. split-noise，噪声主题的引入，以及引入多少（百分比），目前为0.5

目前正在服务器跑...
